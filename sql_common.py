# coding=utf8
import urlparse
import urllib
import xml.sax
from xml.dom.minidom import parse
import xml.dom.minidom
import re
import requests
from difflib import *
import sys

reload(sys)
sys.setdefaultencoding('utf8')

def read_payload():
    global sql_info
    DOMTree = xml.dom.minidom.parse('.\Data\sql_payload.xml')
    collection = DOMTree.documentElement

    dbms_collection = collection.getElementsByTagName("dbms")
    for dbms_node in dbms_collection:
        dbms = str(dbms_node.getAttribute("value"))
        sql_info.payload_dict[dbms] = []
        payloads = dbms_node.getElementsByTagName('payload')
        for payload in payloads:
            payload = payload.getAttribute("value")
            sql_info.payload_dict[dbms].append(payload)

def parse_data(data):
    param_list = urlparse.parse_qsl(data, keep_blank_values=True)
    quote_param_list = []
    for parm in param_list:
        #print parm
        quote_param_list.append(((urllib.unquote(parm[0])), (urllib.unquote(parm[1]))))
    return quote_param_list

def check_https(url_info):
    try:
        if url_info['method'] == 'POST':
            req_right_info = url_info.copy()
            req_right_info['url'] = req_right_info['url'].replace(SQLMARK,"")
            req_right_info['data'] = req_right_info['data'].replace(SQLMARK, "")
            #req_right_info['headers'] = {}
            for header in url_info['headers']:
                req_right_info['headers'][header] = (url_info['headers'][header]).replace(SQLMARK, "")
            # 允许allow_redirects，会报https超过最大连接次数
            rsp = requests.post(req_right_info['url'], data=req_right_info['data'], headers=req_right_info['headers'], proxies=g_proxy, timeout=TIMEOUT,verify=True, allow_redirects=True)
        if url_info['method'] == 'GET':
            req_right_info = url_info.copy()
            req_right_info['url'] = req_right_info['url'].replace(SQLMARK,"")
            #req_right_info['headers'] = {}
            # 允许allow_redirects，会报https超过最大连接次数
            rsp = requests.get(req_right_info['url'], headers=req_right_info['headers'], proxies=g_proxy, timeout=TIMEOUT, verify=True,allow_redirects=True)
    except requests.exceptions.SSLError,err:
        print(err)
        return True